{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98928 entries, 1 to 100000\n",
      "Columns: 189 entries, item_id to user_state_Thuringia\n",
      "dtypes: float64(3), int64(4), uint8(182)\n",
      "memory usage: 23.2 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "#os.chdir(\"C:/Users/TonyG/Documents/GitHub/bads/kaggle\")\n",
    "os.chdir(\"C:/Users/erin-/Documents/bads/kaggle\")\n",
    "data = pd.read_pickle('./data/known_cleaned_w_dummies')\n",
    "X = data.drop(\"return\", axis = 1)\n",
    "y = data[\"return\"]\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Preliminary version only: Create test and train sets based on the known dataset via random splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logit Model with Elastic Net Penality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98928 entries, 1 to 100000\n",
      "Columns: 190 entries, item_id to user_state_Thuringia\n",
      "dtypes: bool(1), float64(3), int64(4), uint8(182)\n",
      "memory usage: 23.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "y, X = data[\"return\"], data.drop(axis = 1, labels = \"return\")\n",
    "model_logit = sm.OLS(y, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Boosted Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 with Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#dtrain_data = xgb.DMatrix(X_train, label = y_train)\n",
    "\n",
    "param_grid = {\"max_depth\" : np.arange(1,20),\n",
    "             \"eta\" : stats.uniform(0.1, 0.8),\n",
    "             \"gamma\" : stats.uniform(0.05, 3),\n",
    "             \"lambda\" : stats.uniform(0, 5),\n",
    "             \"alpha\" : stats.uniform(0, 5),\n",
    "             \"colsample_bytree\" : np.arange(0.2, 1, step = 0.1),\n",
    "             \"subsample\" : np.arange(0.5, 1, step = 0.1),\n",
    "             \"n_estimators\" : np.arange(10, 50, step = 5)}\n",
    "    \n",
    "gbm = xgb.XGBClassifier(objective = \"binary:logistic\", \n",
    "             num_parallel_tree = 1, num_boost_round = 80, early_stopping_rounds = 10)\n",
    "metric = \"roc_auc\"\n",
    "n = 100\n",
    "fold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed: 212.9min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 531.7min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 1036.1min\n",
      "[Parallel(n_jobs=7)]: Done 1000 out of 1000 | elapsed: 1305.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBClassifier(early_stopping_rounds=10,\n",
       "                                           num_boost_round=80,\n",
       "                                           num_parallel_tree=10),\n",
       "                   n_iter=100, n_jobs=7,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000218A218ABC8>,\n",
       "                                        'colsample_bytree': array([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                        'eta': <scipy.stats._distn_infrastructure.rv_frozen obje...\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002189873D708>,\n",
       "                                        'lambda': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000218A218A708>,\n",
       "                                        'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19]),\n",
       "                                        'n_estimators': array([10, 15, 20, 25, 30, 35, 40, 45]),\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   random_state=123, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_auc = RandomizedSearchCV(estimator = gbm, n_iter = n, cv = fold, scoring = metric,\n",
    "                                    param_distributions = param_grid, verbose = 1, random_state = 123,\n",
    "                                   n_jobs = 7)\n",
    "randomized_auc.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 2.7630903067955797, 'colsample_bytree': 0.4000000000000001, 'eta': 0.3615745486583717, 'gamma': 0.5881705239639977, 'lambda': 2.3340493873098933, 'max_depth': 2, 'n_estimators': 15, 'subsample': 0.5}\n",
      "Best Score: 0.6747625886800404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "masked_array(data=[3.595751550773865, 2.005087783306018,\n",
       "                   3.158960088435252, 2.4604238839617114,\n",
       "                   1.1725643759114308, 0.7704112092342336,\n",
       "                   3.1197647589605557, 4.927798928053525,\n",
       "                   2.167091196133339, 2.283739584286279,\n",
       "                   1.5748322294534307, 3.617081790949774,\n",
       "                   3.4776476438545547, 4.208349984563581,\n",
       "                   1.7795743285872978, 1.2042794886181225,\n",
       "                   3.3078216833312184, 1.7713233779583926,\n",
       "                   0.01344032287160346, 4.918154424558616,\n",
       "                   0.8053450721460742, 2.73881786314427,\n",
       "                   2.3693592750229744, 4.055195684974514,\n",
       "                   2.511848237228068, 2.9133554393070233,\n",
       "                   2.203214842049366, 2.426984129042013,\n",
       "                   4.6106433051801545, 3.588787811397788,\n",
       "                   3.72390327570883, 2.5565869574909694,\n",
       "                   1.7205596263776406, 2.0864553045167207,\n",
       "                   1.57571511351378, 2.046952062965292, 0.586034189347529,\n",
       "                   1.5677124559477988, 0.9550347768521056,\n",
       "                   1.90157741559478, 3.148638170235236, 2.372973418310874,\n",
       "                   3.258212805394777, 1.7649618520777572,\n",
       "                   4.700145074641368, 0.42411138722616815,\n",
       "                   4.8375566516871285, 2.9374687373975124,\n",
       "                   3.6466119512306783, 4.600746148795024,\n",
       "                   1.9493711516414618, 4.4113805059830815,\n",
       "                   0.7263186698522689, 2.7624020433241663,\n",
       "                   3.6135097106540464, 0.9124991603409577,\n",
       "                   3.8643891525077088, 0.43703871326411403,\n",
       "                   2.106000285850063, 4.548573310216691,\n",
       "                   1.9777219121438865, 1.6539582559225463,\n",
       "                   4.336439929431345, 0.9244301551265433,\n",
       "                   4.341573550862229, 2.6174377416250922,\n",
       "                   4.716002792385764, 2.336651365064355,\n",
       "                   1.0226336171706574, 1.3871198000369267,\n",
       "                   0.44915933536182007, 4.0525672813518545,\n",
       "                   0.0004094380683383747, 1.0641574928457453,\n",
       "                   3.8738897184150805, 4.204458867751466,\n",
       "                   2.023697429868738, 1.4210961726577769,\n",
       "                   3.3058438589849026, 3.73677069461582,\n",
       "                   1.0230856219857565, 0.5505259822270026,\n",
       "                   4.646812455258969, 1.4264051669687388,\n",
       "                   4.478178954343733, 3.145033035350674,\n",
       "                   0.19413052186782742, 0.6091976388370574,\n",
       "                   0.15958993802875687, 3.1295325584258444,\n",
       "                   0.9601507185698377, 4.709034822081272,\n",
       "                   4.65851441480743, 2.3340493873098933, 1.68114947383827,\n",
       "                   0.5203782253462214, 4.611769440555014,\n",
       "                   1.0352502494196654, 1.4146906356370352,\n",
       "                   0.5925949291174076],\n",
       "             mask=[False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False],\n",
       "       fill_value='?',\n",
       "            dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best Parameters:\", randomized_auc.best_params_)\n",
    "print(\"Best Score:\", randomized_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_50 = randomized_auc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6198670210605478"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "preds = randomized_auc.predict(X_test)\n",
    "\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u = pd.read_pickle('./data/unknown_cleaned_w_dummies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = randomized_auc.predict_proba(data_u)[:, 1]\n",
    "predict_unknown = pd.Series(preds, index=data_u[\"item_id\"].index, name='return')\n",
    "predict_unknown.to_csv(\"first_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 with Bayesion optimization CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to use Bayesian optimization to optimize a given function on a given dataset based on given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, gamma, eta, colsample_bytree, lam, alph, est):\n",
    "    params = {'eval_metric': 'auc',\n",
    "              'max_depth': int(max_depth),\n",
    "              'eta': eta,\n",
    "              'gamma': gamma,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'objective' : 'binary:logistic',\n",
    "              'n_estimators' :  int(est),\n",
    "              'lambda' : lam,\n",
    "              'alph' : alph}\n",
    "    # Used around 1000 boosting rounds in the full model\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round = 150, nfold = 10, early_stopping_rounds = 30)\n",
    "    return cv_result['test-auc-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alph    | colsam... |    est    |    eta    |   gamma   |    lam    | max_depth |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 1.815   \u001b[0m | \u001b[0m 0.6438  \u001b[0m | \u001b[0m 57.98   \u001b[0m | \u001b[0m 0.232   \u001b[0m | \u001b[0m 5.491   \u001b[0m | \u001b[0m 1.942   \u001b[0m | \u001b[0m 137.8   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.754   \u001b[0m | \u001b[95m 0.1493  \u001b[0m | \u001b[95m 0.5076  \u001b[0m | \u001b[95m 73.66   \u001b[0m | \u001b[95m 0.114   \u001b[0m | \u001b[95m 1.752   \u001b[0m | \u001b[95m 3.129   \u001b[0m | \u001b[95m 49.96   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7527  \u001b[0m | \u001b[0m 1.169   \u001b[0m | \u001b[0m 0.3318  \u001b[0m | \u001b[0m 54.17   \u001b[0m | \u001b[0m 0.107   \u001b[0m | \u001b[0m 1.027   \u001b[0m | \u001b[0m 1.221   \u001b[0m | \u001b[0m 15.95   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7609  \u001b[0m | \u001b[95m 1.249   \u001b[0m | \u001b[95m 0.3493  \u001b[0m | \u001b[95m 64.56   \u001b[0m | \u001b[95m 0.07483 \u001b[0m | \u001b[95m 2.277   \u001b[0m | \u001b[95m 3.76    \u001b[0m | \u001b[95m 78.19   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7527  \u001b[0m | \u001b[0m 2.875   \u001b[0m | \u001b[0m 0.623   \u001b[0m | \u001b[0m 78.27   \u001b[0m | \u001b[0m 0.03883 \u001b[0m | \u001b[0m 1.958   \u001b[0m | \u001b[0m 1.765   \u001b[0m | \u001b[0m 130.3   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.7619  \u001b[0m | \u001b[95m 1.383   \u001b[0m | \u001b[95m 0.3969  \u001b[0m | \u001b[95m 64.18   \u001b[0m | \u001b[95m 0.04113 \u001b[0m | \u001b[95m 0.9394  \u001b[0m | \u001b[95m 3.153   \u001b[0m | \u001b[95m 77.16   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.724   \u001b[0m | \u001b[0m 2.745   \u001b[0m | \u001b[0m 0.8445  \u001b[0m | \u001b[0m 54.48   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 71.17   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7534  \u001b[0m | \u001b[0m 0.7438  \u001b[0m | \u001b[0m 0.3574  \u001b[0m | \u001b[0m 70.54   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.164   \u001b[0m | \u001b[0m 76.36   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7563  \u001b[0m | \u001b[0m 1.307   \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 65.53   \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 74.46   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7081  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 64.25   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 83.86   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7392  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 65.6    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 3.94    \u001b[0m | \u001b[0m 3.541   \u001b[0m | \u001b[0m 73.91   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.7632  \u001b[0m | \u001b[95m 0.5793  \u001b[0m | \u001b[95m 0.3     \u001b[0m | \u001b[95m 63.29   \u001b[0m | \u001b[95m 0.09236 \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 6.469   \u001b[0m | \u001b[95m 77.97   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7483  \u001b[0m | \u001b[0m 2.601   \u001b[0m | \u001b[0m 0.7418  \u001b[0m | \u001b[0m 61.0    \u001b[0m | \u001b[0m 0.1092  \u001b[0m | \u001b[0m 1.392   \u001b[0m | \u001b[0m 6.262   \u001b[0m | \u001b[0m 76.75   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7457  \u001b[0m | \u001b[0m 1.128   \u001b[0m | \u001b[0m 0.7812  \u001b[0m | \u001b[0m 69.86   \u001b[0m | \u001b[0m 0.2876  \u001b[0m | \u001b[0m 3.506   \u001b[0m | \u001b[0m 6.135   \u001b[0m | \u001b[0m 78.98   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7458  \u001b[0m | \u001b[0m 2.848   \u001b[0m | \u001b[0m 0.7143  \u001b[0m | \u001b[0m 70.13   \u001b[0m | \u001b[0m 0.1812  \u001b[0m | \u001b[0m 0.3816  \u001b[0m | \u001b[0m 3.984   \u001b[0m | \u001b[0m 45.85   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7529  \u001b[0m | \u001b[0m 0.7847  \u001b[0m | \u001b[0m 0.3754  \u001b[0m | \u001b[0m 64.98   \u001b[0m | \u001b[0m 0.2788  \u001b[0m | \u001b[0m 0.3836  \u001b[0m | \u001b[0m 7.873   \u001b[0m | \u001b[0m 82.26   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7514  \u001b[0m | \u001b[0m 1.211   \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 76.51   \u001b[0m | \u001b[0m 0.124   \u001b[0m | \u001b[0m 2.548   \u001b[0m | \u001b[0m 4.943   \u001b[0m | \u001b[0m 55.16   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7474  \u001b[0m | \u001b[0m 0.6693  \u001b[0m | \u001b[0m 0.7528  \u001b[0m | \u001b[0m 77.92   \u001b[0m | \u001b[0m 0.07693 \u001b[0m | \u001b[0m 6.468   \u001b[0m | \u001b[0m 0.5303  \u001b[0m | \u001b[0m 50.94   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7506  \u001b[0m | \u001b[0m 0.4043  \u001b[0m | \u001b[0m 0.4119  \u001b[0m | \u001b[0m 63.16   \u001b[0m | \u001b[0m 0.1434  \u001b[0m | \u001b[0m 5.12    \u001b[0m | \u001b[0m 7.969   \u001b[0m | \u001b[0m 79.56   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7558  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.4543  \u001b[0m | \u001b[0m 78.27   \u001b[0m | \u001b[0m 0.02115 \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 6.538   \u001b[0m | \u001b[0m 49.27   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7537  \u001b[0m | \u001b[0m 0.1368  \u001b[0m | \u001b[0m 0.4542  \u001b[0m | \u001b[0m 79.95   \u001b[0m | \u001b[0m 0.1768  \u001b[0m | \u001b[0m 1.054   \u001b[0m | \u001b[0m 7.739   \u001b[0m | \u001b[0m 44.13   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.755   \u001b[0m | \u001b[0m 1.515   \u001b[0m | \u001b[0m 0.386   \u001b[0m | \u001b[0m 65.64   \u001b[0m | \u001b[0m 0.2298  \u001b[0m | \u001b[0m 0.06457 \u001b[0m | \u001b[0m 6.07    \u001b[0m | \u001b[0m 78.65   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7468  \u001b[0m | \u001b[0m 1.512   \u001b[0m | \u001b[0m 0.4153  \u001b[0m | \u001b[0m 76.17   \u001b[0m | \u001b[0m 0.2833  \u001b[0m | \u001b[0m 4.652   \u001b[0m | \u001b[0m 6.973   \u001b[0m | \u001b[0m 45.57   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7496  \u001b[0m | \u001b[0m 0.528   \u001b[0m | \u001b[0m 0.5061  \u001b[0m | \u001b[0m 62.26   \u001b[0m | \u001b[0m 0.2196  \u001b[0m | \u001b[0m 0.5999  \u001b[0m | \u001b[0m 4.499   \u001b[0m | \u001b[0m 78.92   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7463  \u001b[0m | \u001b[0m 2.108   \u001b[0m | \u001b[0m 0.7123  \u001b[0m | \u001b[0m 78.55   \u001b[0m | \u001b[0m 0.04404 \u001b[0m | \u001b[0m 0.1962  \u001b[0m | \u001b[0m 3.29    \u001b[0m | \u001b[0m 49.0    \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7596  \u001b[0m | \u001b[0m 0.8468  \u001b[0m | \u001b[0m 0.3424  \u001b[0m | \u001b[0m 73.51   \u001b[0m | \u001b[0m 0.06103 \u001b[0m | \u001b[0m 1.684   \u001b[0m | \u001b[0m 7.889   \u001b[0m | \u001b[0m 50.99   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7485  \u001b[0m | \u001b[0m 0.5961  \u001b[0m | \u001b[0m 0.6533  \u001b[0m | \u001b[0m 72.43   \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 3.695   \u001b[0m | \u001b[0m 6.094   \u001b[0m | \u001b[0m 52.49   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7505  \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m 0.4375  \u001b[0m | \u001b[0m 75.12   \u001b[0m | \u001b[0m 0.2531  \u001b[0m | \u001b[0m 0.3811  \u001b[0m | \u001b[0m 5.526   \u001b[0m | \u001b[0m 52.4    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7496  \u001b[0m | \u001b[0m 0.5028  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 76.71   \u001b[0m | \u001b[0m 0.1721  \u001b[0m | \u001b[0m 2.654   \u001b[0m | \u001b[0m 7.818   \u001b[0m | \u001b[0m 51.17   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7538  \u001b[0m | \u001b[0m 2.361   \u001b[0m | \u001b[0m 0.3944  \u001b[0m | \u001b[0m 65.8    \u001b[0m | \u001b[0m 0.2204  \u001b[0m | \u001b[0m 0.3875  \u001b[0m | \u001b[0m 4.261   \u001b[0m | \u001b[0m 76.45   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7554  \u001b[0m | \u001b[0m 0.2788  \u001b[0m | \u001b[0m 0.3795  \u001b[0m | \u001b[0m 71.97   \u001b[0m | \u001b[0m 0.1574  \u001b[0m | \u001b[0m 1.608   \u001b[0m | \u001b[0m 7.022   \u001b[0m | \u001b[0m 47.8    \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7439  \u001b[0m | \u001b[0m 0.1049  \u001b[0m | \u001b[0m 0.8088  \u001b[0m | \u001b[0m 63.19   \u001b[0m | \u001b[0m 0.241   \u001b[0m | \u001b[0m 1.959   \u001b[0m | \u001b[0m 5.714   \u001b[0m | \u001b[0m 75.89   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7429  \u001b[0m | \u001b[0m 0.3878  \u001b[0m | \u001b[0m 0.7793  \u001b[0m | \u001b[0m 63.58   \u001b[0m | \u001b[0m 0.07884 \u001b[0m | \u001b[0m 0.8147  \u001b[0m | \u001b[0m 1.402   \u001b[0m | \u001b[0m 77.35   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7515  \u001b[0m | \u001b[0m 2.925   \u001b[0m | \u001b[0m 0.5913  \u001b[0m | \u001b[0m 64.32   \u001b[0m | \u001b[0m 0.1498  \u001b[0m | \u001b[0m 2.216   \u001b[0m | \u001b[0m 3.969   \u001b[0m | \u001b[0m 77.71   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.7471  \u001b[0m | \u001b[0m 1.342   \u001b[0m | \u001b[0m 0.5511  \u001b[0m | \u001b[0m 73.7    \u001b[0m | \u001b[0m 0.2759  \u001b[0m | \u001b[0m 2.29    \u001b[0m | \u001b[0m 7.974   \u001b[0m | \u001b[0m 48.83   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.742   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 72.49   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 6.947   \u001b[0m | \u001b[0m 50.51   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7442  \u001b[0m | \u001b[0m 1.561   \u001b[0m | \u001b[0m 0.8092  \u001b[0m | \u001b[0m 64.07   \u001b[0m | \u001b[0m 0.08488 \u001b[0m | \u001b[0m 0.1431  \u001b[0m | \u001b[0m 4.136   \u001b[0m | \u001b[0m 79.22   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.754   \u001b[0m | \u001b[0m 2.406   \u001b[0m | \u001b[0m 0.4172  \u001b[0m | \u001b[0m 65.67   \u001b[0m | \u001b[0m 0.1934  \u001b[0m | \u001b[0m 2.929   \u001b[0m | \u001b[0m 3.666   \u001b[0m | \u001b[0m 77.56   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7549  \u001b[0m | \u001b[0m 0.9541  \u001b[0m | \u001b[0m 0.5652  \u001b[0m | \u001b[0m 66.54   \u001b[0m | \u001b[0m 0.05097 \u001b[0m | \u001b[0m 0.4603  \u001b[0m | \u001b[0m 7.431   \u001b[0m | \u001b[0m 73.97   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 2.568   \u001b[0m | \u001b[0m 0.7519  \u001b[0m | \u001b[0m 63.98   \u001b[0m | \u001b[0m 0.0926  \u001b[0m | \u001b[0m 0.182   \u001b[0m | \u001b[0m 7.694   \u001b[0m | \u001b[0m 78.7    \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7521  \u001b[0m | \u001b[0m 2.896   \u001b[0m | \u001b[0m 0.4283  \u001b[0m | \u001b[0m 64.03   \u001b[0m | \u001b[0m 0.1952  \u001b[0m | \u001b[0m 0.7992  \u001b[0m | \u001b[0m 3.821   \u001b[0m | \u001b[0m 75.43   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7575  \u001b[0m | \u001b[0m 0.641   \u001b[0m | \u001b[0m 0.3397  \u001b[0m | \u001b[0m 64.09   \u001b[0m | \u001b[0m 0.09956 \u001b[0m | \u001b[0m 3.925   \u001b[0m | \u001b[0m 4.362   \u001b[0m | \u001b[0m 79.51   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7461  \u001b[0m | \u001b[0m 0.8508  \u001b[0m | \u001b[0m 0.7571  \u001b[0m | \u001b[0m 63.78   \u001b[0m | \u001b[0m 0.1013  \u001b[0m | \u001b[0m 0.06548 \u001b[0m | \u001b[0m 6.715   \u001b[0m | \u001b[0m 76.44   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7516  \u001b[0m | \u001b[0m 0.5444  \u001b[0m | \u001b[0m 0.6314  \u001b[0m | \u001b[0m 64.9    \u001b[0m | \u001b[0m 0.07662 \u001b[0m | \u001b[0m 1.63    \u001b[0m | \u001b[0m 3.326   \u001b[0m | \u001b[0m 76.8    \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7583  \u001b[0m | \u001b[0m 1.112   \u001b[0m | \u001b[0m 0.4418  \u001b[0m | \u001b[0m 64.21   \u001b[0m | \u001b[0m 0.03611 \u001b[0m | \u001b[0m 2.4     \u001b[0m | \u001b[0m 3.949   \u001b[0m | \u001b[0m 77.52   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7486  \u001b[0m | \u001b[0m 1.333   \u001b[0m | \u001b[0m 0.7032  \u001b[0m | \u001b[0m 63.35   \u001b[0m | \u001b[0m 0.2005  \u001b[0m | \u001b[0m 4.235   \u001b[0m | \u001b[0m 5.917   \u001b[0m | \u001b[0m 79.72   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7432  \u001b[0m | \u001b[0m 2.044   \u001b[0m | \u001b[0m 0.8607  \u001b[0m | \u001b[0m 64.52   \u001b[0m | \u001b[0m 0.2574  \u001b[0m | \u001b[0m 3.243   \u001b[0m | \u001b[0m 4.528   \u001b[0m | \u001b[0m 79.18   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7562  \u001b[0m | \u001b[0m 1.606   \u001b[0m | \u001b[0m 0.4165  \u001b[0m | \u001b[0m 74.43   \u001b[0m | \u001b[0m 0.06571 \u001b[0m | \u001b[0m 2.487   \u001b[0m | \u001b[0m 7.627   \u001b[0m | \u001b[0m 51.36   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.754   \u001b[0m | \u001b[0m 0.7454  \u001b[0m | \u001b[0m 0.5606  \u001b[0m | \u001b[0m 65.7    \u001b[0m | \u001b[0m 0.0953  \u001b[0m | \u001b[0m 2.122   \u001b[0m | \u001b[0m 4.321   \u001b[0m | \u001b[0m 78.46   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7491  \u001b[0m | \u001b[0m 2.181   \u001b[0m | \u001b[0m 0.6206  \u001b[0m | \u001b[0m 64.96   \u001b[0m | \u001b[0m 0.1601  \u001b[0m | \u001b[0m 1.306   \u001b[0m | \u001b[0m 2.712   \u001b[0m | \u001b[0m 76.63   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7501  \u001b[0m | \u001b[0m 0.2462  \u001b[0m | \u001b[0m 0.5324  \u001b[0m | \u001b[0m 62.91   \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 2.949   \u001b[0m | \u001b[0m 4.965   \u001b[0m | \u001b[0m 79.36   \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (1.9756202403999392, 0.6775805732019051, 73.24357559245621, 0.033177954969880054, 2.666386372743057, 6.711916964261635, 52.26288154690063)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-270089c76eb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                              'est' : (10, 80)})\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Optimally needs quite a few more initiation points and number of iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mxgb_bo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-d4df075d484f>\u001b[0m in \u001b[0;36mxgb_evaluate\u001b[1;34m(max_depth, gamma, eta, colsample_bytree, lam, alph, est)\u001b[0m\n\u001b[0;32m     10\u001b[0m               'alph' : alph}\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Used around 1000 boosting rounds in the full model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mcv_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test-auc-mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    443\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (3, 200), \n",
    "                                             'gamma': (0, 8),\n",
    "                                             'colsample_bytree': (0.3, 0.9),\n",
    "                                             'eta' : (0.001, 0.3),\n",
    "                                             'lam' : (0.1, 8),\n",
    "                                             'alph' : (0.1, 3),\n",
    "                                             'est' : (10, 80)})\n",
    "# Optimally needs quite a few more initiation points and number of iterations\n",
    "xgb_bo.maximize(init_points = 5, n_iter = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_bo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5354f7bea34d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_bo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#params['max_depth'] = int(params['max_depth'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#params[\"params\"][\"n_estimators\"] = int(params[\"params\"][\"est\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objective'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary:logistic'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_bo' is not defined"
     ]
    }
   ],
   "source": [
    "params = xgb_bo.max\n",
    "#params['max_depth'] = int(params['max_depth'])\n",
    "params[\"params\"][\"max_depth\"] = int(params[\"params\"][\"max_depth\"])\n",
    "#params[\"params\"][\"n_estimators\"] = int(params[\"params\"][\"est\"])\n",
    "params[\"params\"]['objective'] = 'binary:logistic'\n",
    "params[\"params\"].pop(\"est\")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  {'alpha': 0.5793037571735223,\n",
    "\n",
    "  'colsample_bytree': 0.3,\n",
    "\n",
    "  'eta': 0.11,\n",
    "\n",
    "  'gamma': 0.0,\n",
    "\n",
    "  'lambda': 6.468522967337128,\n",
    "\n",
    "  'max_depth': 77,\n",
    "\n",
    "  'objective': 'binary:logistic'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train model with optimal parameters and calculate auc for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:27:36] WARNING: D:\\Build\\xgboost\\xgboost-1.3.1.git\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7745377371183007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opt = xgb.train(params, dtrain, num_boost_round = 400)\n",
    "\n",
    "preds = model_opt.predict(dtest)\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u = pd.read_pickle('./data/unknown_cleaned_w_dummies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_opt.predict(xgb.DMatrix(data_u))\n",
    "predict_unknown = pd.Series(preds, index=data_u[\"item_id\"].index, name='return')\n",
    "predict_unknown.to_csv(\"sixth_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 with a genetic algorithm (doesn't work because of data formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 123)\n",
    "X_train = X_train.fillna(-999)\n",
    "y_train = y_train.fillna(-999)\n",
    "\n",
    "# Define Hyperparams to tune\n",
    "params = {\"max_depth\" : list(np.linspace(10,200, dtype = int)), \n",
    "         \"learning_rate\" : list(np.arange(0.01, 0.8, step = 0.05)),\n",
    "         \"max_features\" : [\"auto\", \"sqrt\", \"log2\"],\n",
    "         #\"ccp_alpha\" : list(np.arange(0.01, 0.5, step = 0.05)),\n",
    "         #\"loss\" : [\"deviance\", \"exponential\"],\n",
    "         \"min_samples_split\" : list(np.linspace(2, 60, num = 20, dtype = int))}\n",
    "             #\"lambda\" : list(np.arange(0.5, 8, step = 0.05)),\n",
    "             #\"alpha\" : list(np.arange(0.5, 8, step = 0.05)),\n",
    "             #\"colsample_bytree\" : np.arange(0.2, 0.9, step = 0.1)}\n",
    "             #\"n_estimators\" : list(np.arange(10,80, step = 10))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find optimal model via evolutionary algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d0178d78564f8387247e9b38441715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -inf\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    741\u001b[0m                     \u001b[0mper_generation_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_periodic_pipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m                     \u001b[0mlog_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_file_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    743\u001b[0m                 )\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\gp_deap.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[1;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, pbar, stats, halloffame, verbose, per_generation_function, log_file)\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mper_generation_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[0mper_generation_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_check_periodic_pipeline\u001b[1;34m(self, gen)\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \"\"\"\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiodic_checkpoint_folder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    837\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 raise RuntimeError('There was an error in the TPOT optimization '\n\u001b[0m\u001b[0;32m    839\u001b[0m                                    \u001b[1;34m'process. This could be because the data was '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-8fa4745faf99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                  cv = 10, scoring = 'roc_auc')\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtpot_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;31m# raise the exception if it's our last attempt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    762\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m                     \u001b[1;31m# Delete the temporary cache before exiting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    836\u001b[0m                                                     error_score=\"raise\")\n\u001b[0;32m    837\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 raise RuntimeError('There was an error in the TPOT optimization '\n\u001b[0m\u001b[0;32m    839\u001b[0m                                    \u001b[1;34m'process. This could be because the data was '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m                                    \u001b[1;34m'not formatted properly, or because data for '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/"
     ]
    }
   ],
   "source": [
    "tpot_classifier = TPOTClassifier(generations= 2, population_size = 5, offspring_size = 2, mutation_rate = 0.9, crossover_rate = 0.1,\n",
    "                                 verbosity= 2, early_stop = 12, n_jobs = 7, random_state = 123,\n",
    "                                 config_dict =\n",
    "                                 {'sklearn.ensemble.GradientBoostingClassifier': params}, \n",
    "                                 cv = 10, scoring = 'roc_auc')\n",
    "\n",
    "tpot_classifier.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
