{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98928 entries, 1 to 100000\n",
      "Data columns (total 80 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   item_id                                   98928 non-null  int64  \n",
      " 1   brand_id                                  98928 non-null  int64  \n",
      " 2   item_price                                98928 non-null  float64\n",
      " 3   user_id                                   98928 non-null  int64  \n",
      " 4   time_to_delivery                          89610 non-null  float64\n",
      " 5   user_age                                  90292 non-null  float64\n",
      " 6   customer_age                              98928 non-null  int64  \n",
      " 7   item_size_10                              98928 non-null  uint8  \n",
      " 8   item_size_24                              98928 non-null  uint8  \n",
      " 9   item_size_34                              98928 non-null  uint8  \n",
      " 10  item_size_35                              98928 non-null  uint8  \n",
      " 11  item_size_37                              98928 non-null  uint8  \n",
      " 12  item_size_38                              98928 non-null  uint8  \n",
      " 13  item_size_39                              98928 non-null  uint8  \n",
      " 14  item_size_45                              98928 non-null  uint8  \n",
      " 15  item_size_46                              98928 non-null  uint8  \n",
      " 16  item_size_48                              98928 non-null  uint8  \n",
      " 17  item_size_5                               98928 non-null  uint8  \n",
      " 18  item_size_6                               98928 non-null  uint8  \n",
      " 19  item_size_6+                              98928 non-null  uint8  \n",
      " 20  item_size_7+                              98928 non-null  uint8  \n",
      " 21  item_size_8                               98928 non-null  uint8  \n",
      " 22  item_size_8+                              98928 non-null  uint8  \n",
      " 23  item_size_9+                              98928 non-null  uint8  \n",
      " 24  item_size_Other                           98928 non-null  uint8  \n",
      " 25  item_size_l                               98928 non-null  uint8  \n",
      " 26  item_size_m                               98928 non-null  uint8  \n",
      " 27  item_size_s                               98928 non-null  uint8  \n",
      " 28  item_size_unsized                         98928 non-null  uint8  \n",
      " 29  item_size_xl                              98928 non-null  uint8  \n",
      " 30  item_size_xxl                             98928 non-null  uint8  \n",
      " 31  item_color_Other                          98928 non-null  uint8  \n",
      " 32  item_color_aquamarine                     98928 non-null  uint8  \n",
      " 33  item_color_ash                            98928 non-null  uint8  \n",
      " 34  item_color_aubergine                      98928 non-null  uint8  \n",
      " 35  item_color_azure                          98928 non-null  uint8  \n",
      " 36  item_color_basalt                         98928 non-null  uint8  \n",
      " 37  item_color_beige                          98928 non-null  uint8  \n",
      " 38  item_color_berry                          98928 non-null  uint8  \n",
      " 39  item_color_black                          98928 non-null  uint8  \n",
      " 40  item_color_blau                           98928 non-null  uint8  \n",
      " 41  item_color_blue                           98928 non-null  uint8  \n",
      " 42  item_color_coral                          98928 non-null  uint8  \n",
      " 43  item_color_curry                          98928 non-null  uint8  \n",
      " 44  item_color_dark denim                     98928 non-null  uint8  \n",
      " 45  item_color_green                          98928 non-null  uint8  \n",
      " 46  item_color_khaki                          98928 non-null  uint8  \n",
      " 47  item_color_magenta                        98928 non-null  uint8  \n",
      " 48  item_color_mocca                          98928 non-null  uint8  \n",
      " 49  item_color_navy                           98928 non-null  uint8  \n",
      " 50  item_color_olive                          98928 non-null  uint8  \n",
      " 51  item_color_orange                         98928 non-null  uint8  \n",
      " 52  item_color_pallid                         98928 non-null  uint8  \n",
      " 53  item_color_petrol                         98928 non-null  uint8  \n",
      " 54  item_color_pink                           98928 non-null  uint8  \n",
      " 55  item_color_purple                         98928 non-null  uint8  \n",
      " 56  item_color_red                            98928 non-null  uint8  \n",
      " 57  item_color_stained                        98928 non-null  uint8  \n",
      " 58  item_color_turquoise                      98928 non-null  uint8  \n",
      " 59  item_color_white                          98928 non-null  uint8  \n",
      " 60  item_color_yellow                         98928 non-null  uint8  \n",
      " 61  user_title_Family                         98928 non-null  uint8  \n",
      " 62  user_title_Mr                             98928 non-null  uint8  \n",
      " 63  user_title_Mrs                            98928 non-null  uint8  \n",
      " 64  user_state_Baden-Wuerttemberg             98928 non-null  uint8  \n",
      " 65  user_state_Bavaria                        98928 non-null  uint8  \n",
      " 66  user_state_Berlin                         98928 non-null  uint8  \n",
      " 67  user_state_Brandenburg                    98928 non-null  uint8  \n",
      " 68  user_state_Bremen                         98928 non-null  uint8  \n",
      " 69  user_state_Hamburg                        98928 non-null  uint8  \n",
      " 70  user_state_Hesse                          98928 non-null  uint8  \n",
      " 71  user_state_Lower Saxony                   98928 non-null  uint8  \n",
      " 72  user_state_Mecklenburg-Western Pomerania  98928 non-null  uint8  \n",
      " 73  user_state_North Rhine-Westphalia         98928 non-null  uint8  \n",
      " 74  user_state_Rhineland-Palatinate           98928 non-null  uint8  \n",
      " 75  user_state_Saarland                       98928 non-null  uint8  \n",
      " 76  user_state_Saxony                         98928 non-null  uint8  \n",
      " 77  user_state_Saxony-Anhalt                  98928 non-null  uint8  \n",
      " 78  user_state_Schleswig-Holstein             98928 non-null  uint8  \n",
      " 79  user_state_Thuringia                      98928 non-null  uint8  \n",
      "dtypes: float64(3), int64(4), uint8(73)\n",
      "memory usage: 12.9 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "os.chdir(\"C:/Users/TonyG/Documents/GitHub/bads/kaggle\")\n",
    "#os.chdir(\"C:/Users/erin-/Documents/bads/kaggle\")\n",
    "data = pd.read_pickle('./data/known_cleaned_w_dummies')\n",
    "X = data.drop(\"return\", axis = 1)\n",
    "y = data[\"return\"]\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Preliminary version only: Create test and train sets based on the known dataset via random splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Boosted Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 with Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#dtrain_data = xgb.DMatrix(X_train, label = y_train)\n",
    "\n",
    "param_grid = {\"max_depth\" : np.arange(20,100, step = 5),\n",
    "             \"eta\" : stats.uniform(0.01, 0.4),\n",
    "             \"gamma\" : stats.uniform(0.05, 3),\n",
    "             \"lambda\" : stats.uniform(0, 8),\n",
    "             \"alpha\" : stats.uniform(0, 8),\n",
    "             \"colsample_bytree\" : np.arange(0.2, 1, step = 0.1),\n",
    "             \"n_estimators\" : np.arange(10, 200, step = 10)}\n",
    "    \n",
    "gbm = xgb.XGBClassifier(objective = \"binary:logistic\", \n",
    "             num_parallel_tree = 1, num_boost_round = 35, early_stopping_rounds = 10)\n",
    "metric = \"roc_auc\"\n",
    "n = 160\n",
    "fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=7)]: Done 114 tasks      | elapsed: 104.3min\n",
      "[Parallel(n_jobs=7)]: Done 274 tasks      | elapsed: 218.9min\n",
      "[Parallel(n_jobs=7)]: Done 498 tasks      | elapsed: 424.4min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 636.6min\n",
      "[Parallel(n_jobs=7)]: Done 800 out of 800 | elapsed: 646.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(early_stopping_rounds=10,\n",
       "                                           num_boost_round=35,\n",
       "                                           num_parallel_tree=1),\n",
       "                   n_iter=160, n_jobs=7,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000012F72699B48>,\n",
       "                                        'colsample_bytree': array([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                        'eta': <scipy.stats._distn_infrastructure.rv_frozen object...\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000012F70D87408>,\n",
       "                                        'lambda': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000012F726997C8>,\n",
       "                                        'max_depth': array([20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]),\n",
       "                                        'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190])},\n",
       "                   random_state=123, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_auc = RandomizedSearchCV(estimator = gbm, n_iter = n, cv = fold, scoring = metric,\n",
    "                                    param_distributions = param_grid, verbose = 3, random_state = 123,\n",
    "                                   n_jobs = 7)\n",
    "randomized_auc.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 5.179081164586749, 'colsample_bytree': 0.8000000000000003, 'eta': 0.021776051459879167, 'gamma': 2.0530173316629945, 'lambda': 1.2872414745855947, 'max_depth': 25, 'n_estimators': 10}\n",
      "Best Score: 0.6199544234282922\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", randomized_auc.best_params_)\n",
    "print(\"Best Score:\", randomized_auc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a new boosted tree with higher boosting rounds and optimal parameters found by random search and save predictions for unknown for csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "name_ = datetime.datetime.now().strftime('%y_%m_%d-%I_%M') # For prediction csv name\n",
    "\n",
    "data_u = pd.read_pickle('./data/unknown_cleaned_w_dummies') # load in unknown data\n",
    "params = randomized_auc.best_params_ # retrieve optimal parameters\n",
    "params[\"objective\"] = \"binary:logistic\"  # Add Objective\n",
    "dtrain_total = xgb.DMatrix(X, label = y) # Create DMatrix of known data\n",
    "dtest_unknown = xgb.DMatrix(data_u) # Create DMatrix of unknown data\n",
    "\n",
    "model_opt = xgb.train(params = params, dtrain = dtrain_total,\n",
    "                      num_boost_round = 400) # Fit a boosted tree but with a higher number if iterations\n",
    "\n",
    "# Create predictions and save\n",
    "preds = model_opt.predict(dtest_unknown)\n",
    "predict_unknown = pd.Series(preds, index=data_u[\"item_id\"].index, name='return')\n",
    "predict_unknown.to_csv(\"\".join([name_, \"_pred.csv\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9455351838685127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "preds = randomized_auc.predict(X_test)\n",
    "\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u = pd.read_pickle('./data/unknown_cleaned_w_dummies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = randomized_auc.predict_proba(data_u)[:, 1]\n",
    "predict_unknown = pd.Series(preds, index=data_u[\"item_id\"].index, name='return')\n",
    "predict_unknown.to_csv(\"230121_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 with Bayesion optimization CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to use Bayesian optimization to optimize a given function on a given dataset based on given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, gamma, eta, colsample_bytree, lam, alph, est):\n",
    "    params = {'eval_metric': 'auc',\n",
    "              'max_depth': int(max_depth),\n",
    "              'eta': eta,\n",
    "              'gamma': gamma,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'objective' : 'binary:logistic',\n",
    "              'n_estimators' :  int(est),\n",
    "              'lambda' : lam,\n",
    "              'alph' : alph}\n",
    "    # Used around 1000 boosting rounds in the full model\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round = 150, nfold = 10, early_stopping_rounds = 30)\n",
    "    return cv_result['test-auc-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alph    | colsam... |    est    |    eta    |   gamma   |    lam    | max_depth |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7489  \u001b[0m | \u001b[0m 1.815   \u001b[0m | \u001b[0m 0.6438  \u001b[0m | \u001b[0m 57.98   \u001b[0m | \u001b[0m 0.232   \u001b[0m | \u001b[0m 5.491   \u001b[0m | \u001b[0m 1.942   \u001b[0m | \u001b[0m 137.8   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.754   \u001b[0m | \u001b[95m 0.1493  \u001b[0m | \u001b[95m 0.5076  \u001b[0m | \u001b[95m 73.66   \u001b[0m | \u001b[95m 0.114   \u001b[0m | \u001b[95m 1.752   \u001b[0m | \u001b[95m 3.129   \u001b[0m | \u001b[95m 49.96   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7527  \u001b[0m | \u001b[0m 1.169   \u001b[0m | \u001b[0m 0.3318  \u001b[0m | \u001b[0m 54.17   \u001b[0m | \u001b[0m 0.107   \u001b[0m | \u001b[0m 1.027   \u001b[0m | \u001b[0m 1.221   \u001b[0m | \u001b[0m 15.95   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7609  \u001b[0m | \u001b[95m 1.249   \u001b[0m | \u001b[95m 0.3493  \u001b[0m | \u001b[95m 64.56   \u001b[0m | \u001b[95m 0.07483 \u001b[0m | \u001b[95m 2.277   \u001b[0m | \u001b[95m 3.76    \u001b[0m | \u001b[95m 78.19   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7527  \u001b[0m | \u001b[0m 2.875   \u001b[0m | \u001b[0m 0.623   \u001b[0m | \u001b[0m 78.27   \u001b[0m | \u001b[0m 0.03883 \u001b[0m | \u001b[0m 1.958   \u001b[0m | \u001b[0m 1.765   \u001b[0m | \u001b[0m 130.3   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.7619  \u001b[0m | \u001b[95m 1.383   \u001b[0m | \u001b[95m 0.3969  \u001b[0m | \u001b[95m 64.18   \u001b[0m | \u001b[95m 0.04113 \u001b[0m | \u001b[95m 0.9394  \u001b[0m | \u001b[95m 3.153   \u001b[0m | \u001b[95m 77.16   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.724   \u001b[0m | \u001b[0m 2.745   \u001b[0m | \u001b[0m 0.8445  \u001b[0m | \u001b[0m 54.48   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 71.17   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7534  \u001b[0m | \u001b[0m 0.7438  \u001b[0m | \u001b[0m 0.3574  \u001b[0m | \u001b[0m 70.54   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.164   \u001b[0m | \u001b[0m 76.36   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7563  \u001b[0m | \u001b[0m 1.307   \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 65.53   \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 74.46   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7081  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 64.25   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 83.86   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7392  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 65.6    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 3.94    \u001b[0m | \u001b[0m 3.541   \u001b[0m | \u001b[0m 73.91   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.7632  \u001b[0m | \u001b[95m 0.5793  \u001b[0m | \u001b[95m 0.3     \u001b[0m | \u001b[95m 63.29   \u001b[0m | \u001b[95m 0.09236 \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 6.469   \u001b[0m | \u001b[95m 77.97   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7483  \u001b[0m | \u001b[0m 2.601   \u001b[0m | \u001b[0m 0.7418  \u001b[0m | \u001b[0m 61.0    \u001b[0m | \u001b[0m 0.1092  \u001b[0m | \u001b[0m 1.392   \u001b[0m | \u001b[0m 6.262   \u001b[0m | \u001b[0m 76.75   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7457  \u001b[0m | \u001b[0m 1.128   \u001b[0m | \u001b[0m 0.7812  \u001b[0m | \u001b[0m 69.86   \u001b[0m | \u001b[0m 0.2876  \u001b[0m | \u001b[0m 3.506   \u001b[0m | \u001b[0m 6.135   \u001b[0m | \u001b[0m 78.98   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7458  \u001b[0m | \u001b[0m 2.848   \u001b[0m | \u001b[0m 0.7143  \u001b[0m | \u001b[0m 70.13   \u001b[0m | \u001b[0m 0.1812  \u001b[0m | \u001b[0m 0.3816  \u001b[0m | \u001b[0m 3.984   \u001b[0m | \u001b[0m 45.85   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7529  \u001b[0m | \u001b[0m 0.7847  \u001b[0m | \u001b[0m 0.3754  \u001b[0m | \u001b[0m 64.98   \u001b[0m | \u001b[0m 0.2788  \u001b[0m | \u001b[0m 0.3836  \u001b[0m | \u001b[0m 7.873   \u001b[0m | \u001b[0m 82.26   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7514  \u001b[0m | \u001b[0m 1.211   \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 76.51   \u001b[0m | \u001b[0m 0.124   \u001b[0m | \u001b[0m 2.548   \u001b[0m | \u001b[0m 4.943   \u001b[0m | \u001b[0m 55.16   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7474  \u001b[0m | \u001b[0m 0.6693  \u001b[0m | \u001b[0m 0.7528  \u001b[0m | \u001b[0m 77.92   \u001b[0m | \u001b[0m 0.07693 \u001b[0m | \u001b[0m 6.468   \u001b[0m | \u001b[0m 0.5303  \u001b[0m | \u001b[0m 50.94   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7506  \u001b[0m | \u001b[0m 0.4043  \u001b[0m | \u001b[0m 0.4119  \u001b[0m | \u001b[0m 63.16   \u001b[0m | \u001b[0m 0.1434  \u001b[0m | \u001b[0m 5.12    \u001b[0m | \u001b[0m 7.969   \u001b[0m | \u001b[0m 79.56   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7558  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.4543  \u001b[0m | \u001b[0m 78.27   \u001b[0m | \u001b[0m 0.02115 \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 6.538   \u001b[0m | \u001b[0m 49.27   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7537  \u001b[0m | \u001b[0m 0.1368  \u001b[0m | \u001b[0m 0.4542  \u001b[0m | \u001b[0m 79.95   \u001b[0m | \u001b[0m 0.1768  \u001b[0m | \u001b[0m 1.054   \u001b[0m | \u001b[0m 7.739   \u001b[0m | \u001b[0m 44.13   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.755   \u001b[0m | \u001b[0m 1.515   \u001b[0m | \u001b[0m 0.386   \u001b[0m | \u001b[0m 65.64   \u001b[0m | \u001b[0m 0.2298  \u001b[0m | \u001b[0m 0.06457 \u001b[0m | \u001b[0m 6.07    \u001b[0m | \u001b[0m 78.65   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7468  \u001b[0m | \u001b[0m 1.512   \u001b[0m | \u001b[0m 0.4153  \u001b[0m | \u001b[0m 76.17   \u001b[0m | \u001b[0m 0.2833  \u001b[0m | \u001b[0m 4.652   \u001b[0m | \u001b[0m 6.973   \u001b[0m | \u001b[0m 45.57   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7496  \u001b[0m | \u001b[0m 0.528   \u001b[0m | \u001b[0m 0.5061  \u001b[0m | \u001b[0m 62.26   \u001b[0m | \u001b[0m 0.2196  \u001b[0m | \u001b[0m 0.5999  \u001b[0m | \u001b[0m 4.499   \u001b[0m | \u001b[0m 78.92   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7463  \u001b[0m | \u001b[0m 2.108   \u001b[0m | \u001b[0m 0.7123  \u001b[0m | \u001b[0m 78.55   \u001b[0m | \u001b[0m 0.04404 \u001b[0m | \u001b[0m 0.1962  \u001b[0m | \u001b[0m 3.29    \u001b[0m | \u001b[0m 49.0    \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7596  \u001b[0m | \u001b[0m 0.8468  \u001b[0m | \u001b[0m 0.3424  \u001b[0m | \u001b[0m 73.51   \u001b[0m | \u001b[0m 0.06103 \u001b[0m | \u001b[0m 1.684   \u001b[0m | \u001b[0m 7.889   \u001b[0m | \u001b[0m 50.99   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7485  \u001b[0m | \u001b[0m 0.5961  \u001b[0m | \u001b[0m 0.6533  \u001b[0m | \u001b[0m 72.43   \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 3.695   \u001b[0m | \u001b[0m 6.094   \u001b[0m | \u001b[0m 52.49   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7505  \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m 0.4375  \u001b[0m | \u001b[0m 75.12   \u001b[0m | \u001b[0m 0.2531  \u001b[0m | \u001b[0m 0.3811  \u001b[0m | \u001b[0m 5.526   \u001b[0m | \u001b[0m 52.4    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7496  \u001b[0m | \u001b[0m 0.5028  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 76.71   \u001b[0m | \u001b[0m 0.1721  \u001b[0m | \u001b[0m 2.654   \u001b[0m | \u001b[0m 7.818   \u001b[0m | \u001b[0m 51.17   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7538  \u001b[0m | \u001b[0m 2.361   \u001b[0m | \u001b[0m 0.3944  \u001b[0m | \u001b[0m 65.8    \u001b[0m | \u001b[0m 0.2204  \u001b[0m | \u001b[0m 0.3875  \u001b[0m | \u001b[0m 4.261   \u001b[0m | \u001b[0m 76.45   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7554  \u001b[0m | \u001b[0m 0.2788  \u001b[0m | \u001b[0m 0.3795  \u001b[0m | \u001b[0m 71.97   \u001b[0m | \u001b[0m 0.1574  \u001b[0m | \u001b[0m 1.608   \u001b[0m | \u001b[0m 7.022   \u001b[0m | \u001b[0m 47.8    \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7439  \u001b[0m | \u001b[0m 0.1049  \u001b[0m | \u001b[0m 0.8088  \u001b[0m | \u001b[0m 63.19   \u001b[0m | \u001b[0m 0.241   \u001b[0m | \u001b[0m 1.959   \u001b[0m | \u001b[0m 5.714   \u001b[0m | \u001b[0m 75.89   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7429  \u001b[0m | \u001b[0m 0.3878  \u001b[0m | \u001b[0m 0.7793  \u001b[0m | \u001b[0m 63.58   \u001b[0m | \u001b[0m 0.07884 \u001b[0m | \u001b[0m 0.8147  \u001b[0m | \u001b[0m 1.402   \u001b[0m | \u001b[0m 77.35   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7515  \u001b[0m | \u001b[0m 2.925   \u001b[0m | \u001b[0m 0.5913  \u001b[0m | \u001b[0m 64.32   \u001b[0m | \u001b[0m 0.1498  \u001b[0m | \u001b[0m 2.216   \u001b[0m | \u001b[0m 3.969   \u001b[0m | \u001b[0m 77.71   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.7471  \u001b[0m | \u001b[0m 1.342   \u001b[0m | \u001b[0m 0.5511  \u001b[0m | \u001b[0m 73.7    \u001b[0m | \u001b[0m 0.2759  \u001b[0m | \u001b[0m 2.29    \u001b[0m | \u001b[0m 7.974   \u001b[0m | \u001b[0m 48.83   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.742   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 72.49   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 6.947   \u001b[0m | \u001b[0m 50.51   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7442  \u001b[0m | \u001b[0m 1.561   \u001b[0m | \u001b[0m 0.8092  \u001b[0m | \u001b[0m 64.07   \u001b[0m | \u001b[0m 0.08488 \u001b[0m | \u001b[0m 0.1431  \u001b[0m | \u001b[0m 4.136   \u001b[0m | \u001b[0m 79.22   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.754   \u001b[0m | \u001b[0m 2.406   \u001b[0m | \u001b[0m 0.4172  \u001b[0m | \u001b[0m 65.67   \u001b[0m | \u001b[0m 0.1934  \u001b[0m | \u001b[0m 2.929   \u001b[0m | \u001b[0m 3.666   \u001b[0m | \u001b[0m 77.56   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7549  \u001b[0m | \u001b[0m 0.9541  \u001b[0m | \u001b[0m 0.5652  \u001b[0m | \u001b[0m 66.54   \u001b[0m | \u001b[0m 0.05097 \u001b[0m | \u001b[0m 0.4603  \u001b[0m | \u001b[0m 7.431   \u001b[0m | \u001b[0m 73.97   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7466  \u001b[0m | \u001b[0m 2.568   \u001b[0m | \u001b[0m 0.7519  \u001b[0m | \u001b[0m 63.98   \u001b[0m | \u001b[0m 0.0926  \u001b[0m | \u001b[0m 0.182   \u001b[0m | \u001b[0m 7.694   \u001b[0m | \u001b[0m 78.7    \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7521  \u001b[0m | \u001b[0m 2.896   \u001b[0m | \u001b[0m 0.4283  \u001b[0m | \u001b[0m 64.03   \u001b[0m | \u001b[0m 0.1952  \u001b[0m | \u001b[0m 0.7992  \u001b[0m | \u001b[0m 3.821   \u001b[0m | \u001b[0m 75.43   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7575  \u001b[0m | \u001b[0m 0.641   \u001b[0m | \u001b[0m 0.3397  \u001b[0m | \u001b[0m 64.09   \u001b[0m | \u001b[0m 0.09956 \u001b[0m | \u001b[0m 3.925   \u001b[0m | \u001b[0m 4.362   \u001b[0m | \u001b[0m 79.51   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7461  \u001b[0m | \u001b[0m 0.8508  \u001b[0m | \u001b[0m 0.7571  \u001b[0m | \u001b[0m 63.78   \u001b[0m | \u001b[0m 0.1013  \u001b[0m | \u001b[0m 0.06548 \u001b[0m | \u001b[0m 6.715   \u001b[0m | \u001b[0m 76.44   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7516  \u001b[0m | \u001b[0m 0.5444  \u001b[0m | \u001b[0m 0.6314  \u001b[0m | \u001b[0m 64.9    \u001b[0m | \u001b[0m 0.07662 \u001b[0m | \u001b[0m 1.63    \u001b[0m | \u001b[0m 3.326   \u001b[0m | \u001b[0m 76.8    \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7583  \u001b[0m | \u001b[0m 1.112   \u001b[0m | \u001b[0m 0.4418  \u001b[0m | \u001b[0m 64.21   \u001b[0m | \u001b[0m 0.03611 \u001b[0m | \u001b[0m 2.4     \u001b[0m | \u001b[0m 3.949   \u001b[0m | \u001b[0m 77.52   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7486  \u001b[0m | \u001b[0m 1.333   \u001b[0m | \u001b[0m 0.7032  \u001b[0m | \u001b[0m 63.35   \u001b[0m | \u001b[0m 0.2005  \u001b[0m | \u001b[0m 4.235   \u001b[0m | \u001b[0m 5.917   \u001b[0m | \u001b[0m 79.72   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7432  \u001b[0m | \u001b[0m 2.044   \u001b[0m | \u001b[0m 0.8607  \u001b[0m | \u001b[0m 64.52   \u001b[0m | \u001b[0m 0.2574  \u001b[0m | \u001b[0m 3.243   \u001b[0m | \u001b[0m 4.528   \u001b[0m | \u001b[0m 79.18   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7562  \u001b[0m | \u001b[0m 1.606   \u001b[0m | \u001b[0m 0.4165  \u001b[0m | \u001b[0m 74.43   \u001b[0m | \u001b[0m 0.06571 \u001b[0m | \u001b[0m 2.487   \u001b[0m | \u001b[0m 7.627   \u001b[0m | \u001b[0m 51.36   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.754   \u001b[0m | \u001b[0m 0.7454  \u001b[0m | \u001b[0m 0.5606  \u001b[0m | \u001b[0m 65.7    \u001b[0m | \u001b[0m 0.0953  \u001b[0m | \u001b[0m 2.122   \u001b[0m | \u001b[0m 4.321   \u001b[0m | \u001b[0m 78.46   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7491  \u001b[0m | \u001b[0m 2.181   \u001b[0m | \u001b[0m 0.6206  \u001b[0m | \u001b[0m 64.96   \u001b[0m | \u001b[0m 0.1601  \u001b[0m | \u001b[0m 1.306   \u001b[0m | \u001b[0m 2.712   \u001b[0m | \u001b[0m 76.63   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7501  \u001b[0m | \u001b[0m 0.2462  \u001b[0m | \u001b[0m 0.5324  \u001b[0m | \u001b[0m 62.91   \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 2.949   \u001b[0m | \u001b[0m 4.965   \u001b[0m | \u001b[0m 79.36   \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (1.9756202403999392, 0.6775805732019051, 73.24357559245621, 0.033177954969880054, 2.666386372743057, 6.711916964261635, 52.26288154690063)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-270089c76eb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                              'est' : (10, 80)})\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Optimally needs quite a few more initiation points and number of iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mxgb_bo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-d4df075d484f>\u001b[0m in \u001b[0;36mxgb_evaluate\u001b[1;34m(max_depth, gamma, eta, colsample_bytree, lam, alph, est)\u001b[0m\n\u001b[0;32m     10\u001b[0m               'alph' : alph}\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Used around 1000 boosting rounds in the full model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mcv_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test-auc-mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    443\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (3, 200), \n",
    "                                             'gamma': (0, 8),\n",
    "                                             'colsample_bytree': (0.3, 0.9),\n",
    "                                             'eta' : (0.001, 0.3),\n",
    "                                             'lam' : (0.1, 8),\n",
    "                                             'alph' : (0.1, 3),\n",
    "                                             'est' : (10, 80)})\n",
    "# Optimally needs quite a few more initiation points and number of iterations\n",
    "xgb_bo.maximize(init_points = 5, n_iter = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_bo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5354f7bea34d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_bo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#params['max_depth'] = int(params['max_depth'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#params[\"params\"][\"n_estimators\"] = int(params[\"params\"][\"est\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objective'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary:logistic'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_bo' is not defined"
     ]
    }
   ],
   "source": [
    "params = xgb_bo.max\n",
    "#params['max_depth'] = int(params['max_depth'])\n",
    "params[\"params\"][\"max_depth\"] = int(params[\"params\"][\"max_depth\"])\n",
    "#params[\"params\"][\"n_estimators\"] = int(params[\"params\"][\"est\"])\n",
    "params[\"params\"]['objective'] = 'binary:logistic'\n",
    "params[\"params\"].pop(\"est\")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  {'alpha': 0.5793037571735223,\n",
    "\n",
    "  'colsample_bytree': 0.3,\n",
    "\n",
    "  'eta': 0.11,\n",
    "\n",
    "  'gamma': 0.0,\n",
    "\n",
    "  'lambda': 6.468522967337128,\n",
    "\n",
    "  'max_depth': 77,\n",
    "\n",
    "  'objective': 'binary:logistic'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train model with optimal parameters and calculate auc for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:27:36] WARNING: D:\\Build\\xgboost\\xgboost-1.3.1.git\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7745377371183007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opt = xgb.train(params, dtrain, num_boost_round = 400)\n",
    "\n",
    "preds = model_opt.predict(dtest)\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u = pd.read_pickle('./data/unknown_cleaned_w_dummies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_opt.predict(xgb.DMatrix(data_u))\n",
    "predict_unknown = pd.Series(preds, index=data_u[\"item_id\"].index, name='return')\n",
    "predict_unknown.to_csv(\"sixth_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 with a genetic algorithm (doesn't work because of data formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Only reduced so far\n",
    "data_reduced = pd.read_pickle('./data/known_cleaned_w_dummies_reduced')\n",
    "data_u_reduced = pd.read_pickle('./data/unknown_cleaned_w_dummies_reduced')\n",
    "X, y = data_reduced.drop(\"return\", axis = 1), data_reduced[\"return\"]\n",
    "X_test = data_u_reduced \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 123)\n",
    "X_train = X_train.fillna(-999) # TPOT cannot handle NA's\n",
    "y_train = y_train.fillna(-999)\n",
    "\n",
    "# Define Hyperparams to tune\n",
    "params = {\"max_depth\" : list(np.linspace(10,200, dtype = int)), \n",
    "         \"learning_rate\" : list(np.arange(0.01, 0.8, step = 0.05)),\n",
    "         \"max_features\" : [\"auto\", \"sqrt\", \"log2\"],\n",
    "         #\"ccp_alpha\" : list(np.arange(0.01, 0.5, step = 0.05)),\n",
    "         #\"loss\" : [\"deviance\", \"exponential\"],\n",
    "         \"min_samples_split\" : list(np.linspace(2, 60, num = 20, dtype = int))}\n",
    "             #\"lambda\" : list(np.arange(0.5, 8, step = 0.05)),\n",
    "             #\"alpha\" : list(np.arange(0.5, 8, step = 0.05)),\n",
    "             #\"colsample_bytree\" : np.arange(0.2, 0.9, step = 0.1)}\n",
    "             #\"n_estimators\" : list(np.arange(10,80, step = 10))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find optimal model via evolutionary algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 operators have been imported by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 0.11.6.post3 of tpot is outdated. Version 0.11.7 was released Wednesday January 06, 2021.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8131106fb89466ca67804f57eda6180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/9 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Program Files\\Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 404, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"D:\\Program Files\\Anaconda\\lib\\multiprocessing\\queues.py\", line 113, in get\n    return _ForkingPickler.loads(res)\n  File \"D:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\__init__.py\", line 27, in <module>\n    from .tpot import TPOTClassifier, TPOTRegressor\n  File \"D:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\tpot.py\", line 31, in <module>\n    from .base import TPOTBase\n  File \"D:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\", line 65, in <module>\n    from .builtins import CombineDFs, StackingEstimator\n  File \"D:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\builtins\\__init__.py\", line 33, in <module>\n    from .nn import PytorchLRClassifier, PytorchMLPClassifier\n  File \"D:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\builtins\\nn.py\", line 43, in <module>\n    import torch\n  File \"D:\\Program Files\\Anaconda\\lib\\site-packages\\torch\\__init__.py\", line 117, in <module>\n    raise err\nOSError: [WinError 1455] Die Auslagerungsdatei ist zu klein, um diesen Vorgang durchzufhren. Error loading \"D:\\Program Files\\Anaconda\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    741\u001b[0m                     \u001b[0mper_generation_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_periodic_pipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m                     \u001b[0mlog_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_file_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    743\u001b[0m                 )\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\gp_deap.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[1;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, pbar, stats, halloffame, verbose, per_generation_function, log_file)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_evaluate_individuals\u001b[1;34m(self, population, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m   1371\u001b[0m                             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial_wrapped_cross_val_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn_pipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msklearn_pipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m                             for sklearn_pipeline in sklearn_pipeline_list[chunk_idx:chunk_idx + chunk_size])\n\u001b[0m\u001b[0;32m   1373\u001b[0m                     \u001b[1;31m# update pbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ecfc190d6886>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                  cv = 10, scoring = 'roc_auc')\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtpot_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;31m# raise the exception if it's our last attempt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    762\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m                     \u001b[1;31m# Delete the temporary cache before exiting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;31m# If user passes CTRL+C in initial generation, self._pareto_front (halloffame) shoule be not updated yet.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;31m# need raise RuntimeError because no pipeline has been optimized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A pipeline has not yet been optimized. Please call fit() first.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "tpot_classifier = TPOTClassifier(generations= 2, population_size = 5, offspring_size = 2, mutation_rate = 0.9, crossover_rate = 0.1,\n",
    "                                 verbosity= 3, early_stop = 12, n_jobs = 7, random_state = 123,\n",
    "                                 config_dict =\n",
    "                                 {'sklearn.ensemble.GradientBoostingClassifier': params}, \n",
    "                                 cv = 10, scoring = 'roc_auc')\n",
    "\n",
    "tpot_classifier.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
